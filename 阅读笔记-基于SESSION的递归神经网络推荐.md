# 阅读笔记-基于SESSION的递归神经网络推荐

 ## Q1 摘要(from paper)

### 我们在一个新领域应用递归神经网络（RNN），即推荐系统。现实生活中的推荐系统经常面临只能基于短期会话数据（例如一个小型运动服装网站）而非长期用户历史（如Netflix情况）来进行推荐的问题。在这种情况下，常受推崇的*矩阵分解*方法准确性不高。实际中通常通过采用物品到物品的推荐来解决这个问题，即推荐相似的物品。我们认为，通过对整个会话进行建模，可以提供更准确的推荐。因此，我们提出了一种基于RNN的会话推荐方法。我们的方法还考虑了任务的实际方面，并对经典RNN进行了几处修改，如引入排名损失函数，使其更适合这一特定问题。在两个数据集上的实验结果显示，与广泛使用的方法相比，我们的方法有明显改进。



## Q2 现存的问题(my statement)

 ### 现在存在的推荐系统方法主要依赖于该时刻的 交互矩阵 ， 使用协同过滤等方法进行推荐  ，  但是 如何把时间也考虑在 推荐中 是现在比较困难的地方。



## Q3 主要贡献 (my statement)

### 作者在这里提出的一种 基于循环神经网络 的 序列推荐的模型 ， 并且对 损失函数进行了稍加修改



## Q4 related work

### **1. 基于 session 的推荐(new point)**

#### 基于会话的推荐系统（session-based recommendation）是一种特殊类型的推荐系统，主要用于处理那些 **无法依靠长期用户历史数据**来进行推荐的情况。这类系统特别适用于短期交互环境，如单次网站访问或短会话期间的用户行为11

#### 在基于会话的推荐中，系统不依赖于用户的持久身份或其长期行为历史，而是仅仅基于用户在当前会话中的行为来进行推荐。这种推荐的关键是捕捉和分析会话中的用户行为模式，如点击、浏览或购买等活动，然后快速地提供相关的推荐以增强用户体验

## 2.precession research(from paper)

### 在推荐系统领域的大部分研究都集中在当用户标识符可用且可以构建清晰的用户档案时的模型上。在这种设置中，**矩阵分解**方法和邻域模型在文献中占据主导地位，也被在线使用。会话推荐中的一种主要方法，以及解决缺失用户档案问题的自然解决方案是物品对物品推荐方法（Sarwar 等人，2001；Linden 等人，2003）。在这种设置中，**从可用的会话数据预计算物品对物品的相似度矩阵，**即在会话中经常一起点击的物品被视为相似。然后在会话期间简单地使用这个相似度矩阵来推荐与用户当前点击的物品最相似的物品。尽管简单，但这种方法已被证明是有效的，并被广泛采用。尽管有效，这些方法只考虑了用户的最后一次点击，实际上忽略了之前点击的信息。**会话推荐的另一种不同方法是马尔可夫决策过程**（MDP）（Shani 等人，2002）。MDP是序贯随机决策问题的模型。MDP定义为四元组〈S, A, Rwd, tr〉，其中S是状态集，A是动作集，Rwd是奖励函数，tr是状态转移函数。在推荐系统中，**动作可以等同于推荐**，最简单的MPD本质上是一阶马尔可夫链，下一个推荐可以基于物品间的转移概率简单计算。在会话推荐中应用马尔可夫链的主要问题是，当试图包括所有可能的用户选择序列时，状态空间很快变得无法管理。**广义因子分解框架（GFF）的扩展版本**（Hidasi & Tikk，2015）能够使用会话数据进行推荐。它通过事件的总和来建模一个会话。它使用两种类型的物品潜在表示，一种表示物品本身，另一种用于表示物品作为会话的一部分。然后，会话被表示为会话中部分物品表示的特征向量的平均值。然而，这种方法没有考虑会话内的任何排序。



### 3 . Precedent deep learning and recommend system(from paper)

### 这段文字讨论了神经网络文献中的一些早期方法，尤其是如何使用限制玻尔兹曼机（RBM）来进行协同过滤。Salakhutdinov等人在2007年的工作中使用RBM来模拟用户-物品交互并执行推荐。这种模型已被证明是表现最佳的**协同过滤模型**之一。深度模型已被用来从非结构化内容如音乐或图片中提取特征，然后这些特征与更传统的协同过滤模型一起使用。在Van den Oord等人2013年的研究中，**使用卷积深度网络从音乐**文件中提取特征，然后在因子模型中使用这些特征。更近期的Wang等人在2015年引入了一种更通用的方法，通过深度网络从任何类型的物品中提取通用内容特征，然后将这些特征整合到标准的协同过滤模型中，以提高推荐性能。**这种方法在用户-物品交互信息不足的情况下似乎特别有用。**(局限性)



## Q4 Solution

###  我们在 基于回话 的推荐模型中使用的基于GRU 的RNN 模型 ， 网络的输入是session的当前状态 ， 而输出是下一状态的物品。会话的状态可以是当前事件的物品，或者是到目前为止会话中的事件。

### 在前一种情况下 使用 1 of n 编码 ， 即输入向量的长度等于 项目的数量 ， 10编码。。

### 后一种设置使用这些表示的加权和，如果事件更早发生，则对其进行折扣。对于稳定性的风险，然后对输入向量进行归一化。

### 作者 希望这种方法可以加强强化的记忆效应 ， 为了防止没有被rnn 很好的捕获， 可以尝试添加额外的嵌入层。



### 这个网络的核心是 GRU 层 ， 可以在最后一层和输出之间添加额外的前馈层。输出是项目的预测偏好，即每个项目在会话中成为下一个的可能性。当使用多个 GRU 层时，前一层的隐藏状态是下一层的输入。



![image-20240417103458410](C:\Users\杜冠辰\AppData\Roaming\Typora\typora-user-images\image-20240417103458410.png)



## session-parallel minibaches



![image-20240417103719784](C:\Users\杜冠辰\AppData\Roaming\Typora\typora-user-images\image-20240417103719784.png)

### 在传统的 NLP 领域中的 活动窗口 在我们的任务并不适用，因为回话的长度可能不同。们的目标是捕捉会话如何随着时间的推移而演变，因此分解为片段是没有意义的。

 ### 首先 我们为会话创建一个顺序 ， 然后 使用 session的第一个事件来形成第一个mini-batch的输入，输出即为下一个序列的事件。第二个小批量由第二个事件组成，以此类推。如果任何会话结束，则下一个可用的会话就放在其位置。

### 这里有一个重要的假设 ： 即每一次的回话都是独立的，因此当发生此切换时，我们会重置适当的隐藏状态。



## sampling on the output

###  文章 仅仅点明为啥对 输出采样是必要的 ， 并没有对其进行详细的步骤说明

### 在输出中 ，仅仅计算了项目的 一小部分的的分数 ， 只会更新一些权重。<u>除了所需的输出之外，我们还需要计算一些负例的分数并修改权重，以便期望的输出排名很高。(不懂)</u>

### 其次，任意缺失事件的自然解释是 用户有大概率不知道该项目的存在，因此没有交互 。用户确实知道这个项目并选择~~“不喜欢”~~ 的概率很低。 所以 ，我们在采样的时候应该对不同受欢迎比例进行采样。

### 其次 ， 我们也没有使用生成的负样本 ， 相反 负样本来自于 其他的训练样本，避免了重复的采样过程。

##### 这样做的优点是 ： 减少了计算时间，简化代码实现 ， 也是基于流行度的采样（这种方法也被认为是基于流行度的采样策略，因为在一个小批量中，一个项目被作为负样本选取的概率与其流行度成正比。这意味着更受欢迎的项目更有可能出现在多个训练样本中，从而有更高的机会被用作负样本。）



## ranking loss

### 在推荐系统中 ， 核心关键就是 基于相关物品性的排名。虽然可是解释称为一个分类任务，但但学习排名的方法（Rendle 等人，2009年；Shi 等人，2012年；Steck，2015年）通常优于其他方法。排名可以是点对点（pointwise）、成对（pairwise）或列表（listwise）。点对点排名**独立评估每个物品的得分或排名**，损失定义为使相关物品的排名应该较低。成对排名比较**一对正负物品的得分或排名**，损失函数确保**正物品的排名应该低于负物品的排名**。列表排名使用所有物品的得分和排名，并将它们与完美的顺序进行比较。由于包括排序，它通常计算成本更高，因此不常使用。此外，如果只有一个相关物品——就像我们的情况一样——列表排名可以通过成对排名来解决。

##### some example

我们有一个电影数据库，其中包括各种类型的电影，每部电影都有相关的特征，如类型、导演、演员、用户评分等。

1. 点对点排名： 对系统的每一个电影评估一个得分，该得分反应了电影与用户喜好的匹配程度
2. 成对排名：系统可以选择一对电影，类比A与类别 B 。如果 用户更加偏好A 类则 A类会始终高于 B了
3. 列表排名： 考虑所有喜欢的电影， 并对其进行排序 ， 尝试得到一个几乎完美的推荐列表。

### 当然 在我们的任务中 ， 我们重点考虑到 点对点损失以及 成对排名损失。在实验中，我们发现点对点排名的稳定性较差but 成对排名的损失表现较好。



### 我们的损失函数 基于 成对排名如下：

![image-20240417114921185](C:\Users\杜冠辰\AppData\Roaming\Typora\typora-user-images\image-20240417114921185.png)

### 这个损失函数的 通过比较用户喜欢的正样本 以及 用户不喜欢的负样本~~进行对比学习 ？？？~~

$N_s$ 是采样的大小 $sigmoid$  是 对 $\hat{r_{s,i}}$指的是 对下一个样本是正样本的推荐得分$\hat{r_{s,j}}$是对下一个样本为负样本的推荐得分。 目的就是 让 i 的得分 大于 j 

![image-20240417120213869](C:\Users\杜冠辰\AppData\Roaming\Typora\typora-user-images\image-20240417120213869.png)

### 这个损失函数 来自于 上述 含有 I的公式 ， 若 {} 中的条较为真 ， 则 值为 1 ， or值为 0 ；； ~~最小化 负样本 大于 正样本的 个数~~  进行损失优化？？ 由于 I函数 不利于 求导 ，我们把它平滑成 SIGMOD 并且 我们加入了 正则项  



## 实验 

